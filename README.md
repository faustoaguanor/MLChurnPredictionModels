<div align="center">

# Customer Churn Prediction in Telecommunications

<img src="https://yachaytech.edu.ec/wp-content/uploads/2023/12/Logo-YT-Azul-Transparencia-220x103-1.png" alt="Yachay Tech Logo" width="300"/>

[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)](https://scikit-learn.org/)
[![XGBoost](https://img.shields.io/badge/XGBoost-337AB7?style=for-the-badge&logo=xgboost&logoColor=white)](https://xgboost.readthedocs.io/)
[![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)](https://streamlit.io/)
[![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)](https://pandas.pydata.org/)
[![Plotly](https://img.shields.io/badge/Plotly-3F4F75?style=for-the-badge&logo=plotly&logoColor=white)](https://plotly.com/)

[![GitHub Repository](https://img.shields.io/badge/GitHub-Repository-181717?style=for-the-badge&logo=github)](https://github.com/faustoguanoj/telco-customer-churn)
[![GitHub Profile](https://img.shields.io/badge/GitHub-Profile-181717?style=for-the-badge&logo=github)](https://github.com/faustoaguanor)

</div>

---

Sistema de predicci贸n de abandono de clientes mediante t茅cnicas de aprendizaje autom谩tico supervisado, desarrollado como proyecto final del curso de Aprendizaje de M谩quina en la Maestr铆a en Ciencia de Datos de la Universidad Yachay Tech.

## Tabla de Contenidos

- [Customer Churn Prediction in Telecommunications](#customer-churn-prediction-in-telecommunications)
  - [Tabla de Contenidos](#tabla-de-contenidos)
  - [Resumen](#resumen)
  - [Modelos Implementados](#modelos-implementados)
  - [Metodolog铆a](#metodolog铆a)
    - [1. Preprocesamiento de Datos](#1-preprocesamiento-de-datos)
    - [2. Selecci贸n de Caracter铆sticas](#2-selecci贸n-de-caracter铆sticas)
    - [3. Validaci贸n](#3-validaci贸n)
  - [Dataset](#dataset)
  - [Estructura del Proyecto](#estructura-del-proyecto)
  - [Instalaci贸n y Uso](#instalaci贸n-y-uso)
    - [Requisitos](#requisitos)
    - [Configuraci贸n del Entorno](#configuraci贸n-del-entorno)
  - [Deployment en Streamlit Cloud](#deployment-en-streamlit-cloud)
    - [Opci贸n 1: Deployment con modelos pre-entrenados](#opci贸n-1-deployment-con-modelos-pre-entrenados)
    - [Opci贸n 2: Entrenar modelos desde la aplicaci贸n](#opci贸n-2-entrenar-modelos-desde-la-aplicaci贸n)
  - [Aplicaci贸n Web Interactiva](#aplicaci贸n-web-interactiva)
    - [ 1. Predicci贸n Individual](#-1-predicci贸n-individual)
    - [ 2. Dashboard de M茅tricas](#-2-dashboard-de-m茅tricas)
    - [ 3. An谩lisis Exploratorio de Datos (EDA)](#-3-an谩lisis-exploratorio-de-datos-eda)
    - [ 4. Entrenamiento de Modelos](#-4-entrenamiento-de-modelos)
  - [Resultados](#resultados)
    - [M茅tricas de Desempe帽o](#m茅tricas-de-desempe帽o)
    - [Comparativa de Modelos](#comparativa-de-modelos)
    - [Caracter铆sticas M谩s Importantes](#caracter铆sticas-m谩s-importantes)
  - [Arquitectura de Pipelines](#arquitectura-de-pipelines)
  - [Hiperpar谩metros](#hiperpar谩metros)
  - [Tecnolog铆as](#tecnolog铆as)
  - [Autor](#autor)

## Resumen

Este trabajo implementa un sistema end-to-end de clasificaci贸n binaria para predecir el abandono de clientes (*customer churn*) en el sector de telecomunicaciones. Se evaluaron tres algoritmos de aprendizaje supervisado con arquitecturas complementarias: Random Forest (ensemble bagging), Support Vector Machines con kernel RBF, y XGBoost (gradient boosting). Cada modelo fue entrenado en dos configuraciones: con el conjunto completo de caracter铆sticas y con las 10 caracter铆sticas m谩s relevantes identificadas mediante an谩lisis de importancia.

## Modelos Implementados

1. **Random Forest**: Ensemble de 200 谩rboles de decisi贸n con profundidad m谩xima de 15 niveles
2. **SVM (Support Vector Machine)**: Clasificador con kernel RBF y estimaci贸n probabil铆stica habilitada
3. **XGBoost**: Gradient boosting con 200 estimadores y tasa de aprendizaje de 0.1

Cada algoritmo cuenta con dos variantes:

- **ALL**: Entrenamiento con las 19 caracter铆sticas del dataset preprocesado
- **TOP**: Entrenamiento con las 10 caracter铆sticas de mayor importancia predictiva

## Metodolog铆a

### 1. Preprocesamiento de Datos

**Pipeline de transformaci贸n**:

- Imputaci贸n de valores faltantes (mediana para variables num茅ricas, moda para categ贸ricas)
- Escalado robusto mediante `RobustScaler` (resistente a valores at铆picos)
- Codificaci贸n one-hot para variables categ贸ricas
- Balanceo de clases mediante SMOTE (*Synthetic Minority Over-sampling Technique*)

### 2. Selecci贸n de Caracter铆sticas

Se aplic贸 an谩lisis de importancia mediante Random Forest para identificar las variables m谩s predictivas. Las 10 caracter铆sticas principales fueron utilizadas para entrenar las versiones optimizadas de cada modelo.

### 3. Validaci贸n

**Estrategia de partici贸n estratificada**:

- Entrenamiento: 60%
- Validaci贸n: 20%
- Prueba: 20%

**M茅tricas de evaluaci贸n**:

- *Accuracy*: Proporci贸n de clasificaciones correctas
- *F1-Score*: Media arm贸nica entre precisi贸n y recall
- *AUC-ROC*: rea bajo la curva caracter铆stica de operaci贸n del receptor
- Matriz de confusi贸n para an谩lisis de errores

## Dataset

**Fuente**: Telco Customer Churn (IBM Sample Data Sets)

El conjunto de datos contiene 7,043 registros de clientes con 19 variables predictoras agrupadas en tres categor铆as:

**Variables demogr谩ficas**: g茅nero, edad (senior citizen), estado civil, dependientes

**Variables de servicio**: antig眉edad (tenure), tipo de internet, servicios complementarios (seguridad, backup, soporte t茅cnico, streaming)

**Variables contractuales**: tipo de contrato, m茅todo de pago, facturaci贸n mensual y total

**Variable objetivo**: Churn (abandono del servicio)

## Estructura del Proyecto

```
.
 app.py                          # Aplicaci贸n web interactiva
 train_models.py                 # Pipeline de entrenamiento
 requirements.txt                # Dependencias del proyecto
 WA_Fn-UseC_-Telco-Customer-Churn.csv
 models/                         # Artefactos generados
     randomforest_all.pkl
     randomforest_top.pkl
     svm_all.pkl
     svm_top.pkl
     xgboost_all.pkl
     xgboost_top.pkl
     preparer.pkl                # Pipeline de preprocesamiento
     top_features.pkl
     label_encoder.pkl
     feature_importance.csv
     test_data.csv
     metrics_summary.csv
```

## Instalaci贸n y Uso

### Requisitos

- Python 3.8+
- Bibliotecas: scikit-learn, XGBoost, imbalanced-learn, Streamlit, Plotly, Pandas, NumPy

### Configuraci贸n del Entorno

```bash
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Entrenar modelos
python train_models.py

# Ejecutar aplicaci贸n web
streamlit run app.py
```

El script de entrenamiento genera 6 pipelines completos (3 algoritmos  2 configuraciones) y guarda las m茅tricas de evaluaci贸n. La aplicaci贸n web se ejecuta en `http://localhost:8501`.

## Deployment en Streamlit Cloud

### Opci贸n 1: Deployment con modelos pre-entrenados

1. **Entrenar modelos localmente**:

   ```bash
   python train_models.py
   ```

2. **Subir al repositorio**:
   - Commit y push de todos los archivos `.pkl` y `.csv` de la carpeta `models/`
   - Asegurar que `requirements.txt` est谩 actualizado

3. **Configurar en Streamlit Cloud**:
   - Acceder a [share.streamlit.io](https://share.streamlit.io)
   - Conectar repositorio de GitHub
   - Seleccionar `app.py` como archivo principal
   - Hacer clic en "Deploy"

### Opci贸n 2: Entrenar modelos desde la aplicaci贸n

1. **Deployar aplicaci贸n sin modelos**:
   - Subir c贸digo a GitHub sin la carpeta `models/`
   - Deployar en Streamlit Cloud

2. **Entrenar en la interfaz web**:
   - Navegar a la pesta帽a " Entrenar Modelos"
   - Cargar el archivo CSV del dataset
   - Configurar par谩metros de entrenamiento
   - Descargar el archivo ZIP con los modelos entrenados

3. **Actualizar el repositorio**:
   - Extraer los archivos del ZIP
   - Subir los archivos `.pkl` a la carpeta `models/` en GitHub
   - Streamlit Cloud redesplegar谩 autom谩ticamente

## Aplicaci贸n Web Interactiva

La interfaz de Streamlit proporciona cuatro m贸dulos principales:

###  1. Predicci贸n Individual

**Funcionalidad**: Sistema de inferencia en tiempo real para evaluaci贸n de riesgo de abandono.

**Caracter铆sticas**:

- Selecci贸n de modelo (Random Forest, SVM, XGBoost) y configuraci贸n (ALL/TOP features)
- Formulario interactivo con validaci贸n de datos de entrada
- Ingreso de caracter铆sticas demogr谩ficas, de servicio y contractuales
- Visualizaci贸n de resultado: clase predicha (Abandonar谩/No Abandonar谩)
- Probabilidad de abandono con indicador visual de riesgo
- Interpretaci贸n autom谩tica del nivel de riesgo (Bajo/Medio/Alto)

**Uso**: Ideal para evaluaci贸n de clientes individuales y toma de decisiones de retenci贸n.

###  2. Dashboard de M茅tricas

**Funcionalidad**: Panel de an谩lisis comparativo de rendimiento de modelos.

**Caracter铆sticas**:

- **Comparaci贸n de m茅tricas**: Gr谩ficos de barras comparativos para Accuracy, F1-Score y AUC-ROC
- **Filtros**: Visualizaci贸n por versi贸n (Todas/ALL features/TOP features)
- **Matrices de confusi贸n**: Heatmaps interactivos para los 6 modelos entrenados
- **An谩lisis de errores**: Visualizaci贸n de verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos
- **Importancia de caracter铆sticas**: Ranking de variables m谩s influyentes con gr谩fico de barras horizontal
- **Selector din谩mico**: Ajuste del n煤mero de caracter铆sticas a visualizar (Top 5 a Top 20)

**Uso**: Evaluaci贸n y selecci贸n del mejor modelo seg煤n m茅tricas de desempe帽o.

###  3. An谩lisis Exploratorio de Datos (EDA)

**Funcionalidad**: Exploraci贸n estad铆stica y visual del dataset.

**Caracter铆sticas**:

- **Selector de alcance**: Visualizaci贸n de todas las variables o solo top features
- **Distribuci贸n de Churn**:
  - Gr谩fico de torta con porcentajes
  - Gr谩fico de barras con conteos absolutos
  - Estad铆sticas de balance de clases
- **Variables num茅ricas**:
  - Histogramas comparativos por clase (Churn/No Churn)
  - Box plots para detecci贸n de outliers
  - An谩lisis de distribuci贸n por variable
- **Variables categ贸ricas**:
  - Gr谩ficos de barras agrupados
  - Comparaci贸n de frecuencias entre clases
  - Identificaci贸n de patrones discriminativos
- **Matriz de correlaci贸n**: Heatmap de correlaciones entre variables num茅ricas
- **Estad铆sticas descriptivas**: Tabla completa con medidas de tendencia central y dispersi贸n

**Uso**: Comprensi贸n del comportamiento de los datos y validaci贸n de supuestos del modelo.

###  4. Entrenamiento de Modelos

**Funcionalidad**: Reentrenamiento del sistema con datasets personalizados.

**Caracter铆sticas**:

- **Carga de datos**: Upload de archivos CSV con vista previa
- **Configuraci贸n de partici贸n**:
  - Tama帽o del conjunto de prueba (10-40%)
  - Semilla aleatoria para reproducibilidad
- **Selecci贸n de algoritmos**: Checkbox para Random Forest, SVM y XGBoost
- **Configuraci贸n de features**: N煤mero de caracter铆sticas principales a seleccionar (5-20)
- **Proceso de entrenamiento**:
  - Barra de progreso por modelo
  - M茅tricas de validaci贸n en tiempo real
  - Resumen de caracter铆sticas m谩s importantes
- **Exportaci贸n**:
  - Descarga de archivo ZIP con todos los modelos entrenados
  - Descarga individual de label encoder y lista de top features
  - M茅tricas de evaluaci贸n en formato CSV

**Uso**: Adaptaci贸n del sistema a nuevos datos o actualizaci贸n de modelos con informaci贸n reciente.

## Resultados

El rendimiento de los modelos se evalu贸 sobre el conjunto de prueba (20% de los datos). Los resultados se encuentran disponibles en el archivo [`models/metrics_summary.csv`](models/metrics_summary.csv) generado durante el entrenamiento.

### M茅tricas de Desempe帽o

Los tres algoritmos demostraron capacidad de generalizaci贸n adecuada, con m茅tricas superiores a 0.75 en Accuracy y AUC-ROC. La configuraci贸n con todas las caracter铆sticas (ALL) generalmente obtiene mejor rendimiento que la versi贸n optimizada (TOP), aunque esta 煤ltima ofrece la ventaja de requerir menos informaci贸n del cliente para realizar predicciones.

### Comparativa de Modelos

Los resultados obtenidos sobre el conjunto de prueba son:

| Modelo | Versi贸n | Accuracy | F1-Score | AUC-ROC |
|--------|---------|----------|----------|---------|
| **Random Forest** | ALL | 0.7665 | 0.5963 | **0.8242** |
| **Random Forest** | TOP | 0.7665 | 0.6079 | **0.8232** |
| **SVM** | ALL | 0.7544 | 0.6023 | 0.8094 |
| **SVM** | TOP | 0.7509 | **0.6147** | 0.8113 |
| **XGBoost** | ALL | **0.7700** | 0.5586 | 0.8021 |
| **XGBoost** | TOP | 0.7530 | 0.5639 | 0.8011 |

**Mejores resultados por m茅trica**:

- **Accuracy**: XGBoost ALL (77.00%)
- **F1-Score**: SVM TOP (61.47%)
- **AUC-ROC**: Random Forest ALL (82.42%)

**An谩lisis**:

- Random Forest demuestra el mejor equilibrio entre discriminaci贸n de clases (AUC-ROC m谩s alto)
- XGBoost obtiene la mayor precisi贸n general pero menor F1-Score
- SVM con caracter铆sticas TOP logra el mejor balance precisi贸n-recall (F1-Score m谩s alto)
- Las versiones TOP mantienen desempe帽o competitivo con solo 10 caracter铆sticas vs 19 completas

### Caracter铆sticas M谩s Importantes

Las 10 caracter铆sticas con mayor importancia predictiva (seg煤n Random Forest) son:

1. **TotalCharges**: Cargos totales acumulados
2. **MonthlyCharges**: Cargos mensuales
3. **tenure**: Antig眉edad del cliente en meses
4. **Contract**: Tipo de contrato
5. **InternetService**: Tipo de servicio de internet
6. **PaymentMethod**: M茅todo de pago
7. **TechSupport**: Soporte t茅cnico contratado
8. **OnlineSecurity**: Servicio de seguridad online
9. **StreamingTV**: Servicio de streaming de TV
10. **PaperlessBilling**: Facturaci贸n electr贸nica

Estas caracter铆sticas son utilizadas en las versiones TOP de los modelos, permitiendo predicciones con menor cantidad de informaci贸n requerida.

## Arquitectura de Pipelines

Cada modelo implementa un pipeline de scikit-learn que encapsula:

1. **Preprocesamiento**: Imputaci贸n, escalado robusto y codificaci贸n one-hot
2. **Selecci贸n de caracter铆sticas**: Filtrado autom谩tico para versiones TOP
3. **Clasificador**: Algoritmo de aprendizaje entrenado

Esta arquitectura garantiza la consistencia entre las fases de entrenamiento e inferencia, eliminando el riesgo de *data leakage* y simplificando el despliegue en producci贸n.

## Hiperpar谩metros

| Modelo | Par谩metros principales |
|--------|------------------------|
| Random Forest | n_estimators=200, max_depth=15, min_samples_split=10 |
| SVM | kernel='rbf', C=1.0, gamma='scale', probability=True |
| XGBoost | n_estimators=200, max_depth=6, learning_rate=0.1 |

## Tecnolog铆as

**Lenguaje**: Python 3.8+

**Bibliotecas principales**: scikit-learn (pipelines, Random Forest, SVM), XGBoost, imbalanced-learn (SMOTE), Streamlit (interfaz web), Plotly (visualizaciones), Pandas, NumPy

## Autor

<div align="center">

**Fausto Guano**

Maestr铆a en Ciencia de Datos
Universidad Yachay Tech

[![GitHub](https://img.shields.io/badge/GitHub-faustoaguanor-181717?style=flat-square&logo=github)](https://github.com/faustoaguanor)
[![Email](https://img.shields.io/badge/Email-Contact-D14836?style=flat-square&logo=gmail&logoColor=white)](mailto:fausto.guano@yachaytech.edu.ec)

</div>

---

## Licencia

Este proyecto est谩 licenciado bajo la Licencia MIT - consulta el archivo [LICENSE](LICENSE) para m谩s detalles.

---

<div align="center">

*Proyecto desarrollado con fines acad茅micos para el curso de Aprendizaje de M谩quina (2025)*

**Universidad Yachay Tech - Maestr铆a en Ciencia de Datos**

</div>
